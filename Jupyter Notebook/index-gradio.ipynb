{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from pinecone import Pinecone, ServerlessSpec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up API keys\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\") or input(\"Enter your OpenAI API key: \")\n",
    "\n",
    "# Set up Pinecone API key\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\") or input(\"Enter your Pinecone API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text\n",
      "0  - 19 things to know before\\nyou go to Tokyo, J...\n",
      "1                         I'm Chris, this is Topher.\n",
      "2                   We are the internet's number one\n",
      "3             human and stuffed panda traveling duo.\n",
      "4                        This is Yellow Productions,\n"
     ]
    }
   ],
   "source": [
    "#Load and flatten the playlist_transcripts.json file.\n",
    "# Load the JSON file\n",
    "with open(\"playlist_transcripts.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Flatten the data to extract only the text\n",
    "texts = []\n",
    "for video_id, transcripts in data.items():\n",
    "    for entry in transcripts:\n",
    "        if isinstance(entry, dict):  # Ensure entry is a dictionary\n",
    "            texts.append(entry[\"text\"])  # Collect only the transcript text\n",
    "\n",
    "# Convert to DataFrame for processing\n",
    "df = pd.DataFrame({\"text\": texts})\n",
    "\n",
    "# Check the structure of the DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 490\n",
      "                                                text\n",
      "0  - 19 things to know before\\nyou go to Tokyo, J...\n",
      "1  city is the friendly limousine bus. It's a big...\n",
      "2  an really understand English, all that well. W...\n",
      "3  you're at a ticket window\\nto buy Shinkansen t...\n",
      "4  e, the staff might be running after you, after...\n"
     ]
    }
   ],
   "source": [
    "# Initialize variables for chunking\n",
    "chunk_size = 4000  # Number of characters per chunk\n",
    "chunk_overlap = 800  # Overlapping characters between chunks\n",
    "chunks = []  # To store the resulting chunks\n",
    "current_chunk = \"\"  # Accumulator for the current chunk\n",
    "\n",
    "# Iterate through all rows in the DataFrame\n",
    "for row in df[\"text\"]:\n",
    "    if len(current_chunk) + len(row) + 1 <= chunk_size:  # Add row if it fits in the current chunk\n",
    "        current_chunk += row + \" \"  # Add a space between sentences\n",
    "    else:\n",
    "        chunks.append(current_chunk.strip())  # Save the full chunk\n",
    "        current_chunk = row + \" \"  # Start a new chunk with overlap\n",
    "        # Add overlap from the end of the previous chunk\n",
    "        if chunk_overlap > 0 and len(chunks[-1]) > chunk_overlap:\n",
    "            current_chunk = chunks[-1][-chunk_overlap:] + current_chunk\n",
    "\n",
    "# Add the last chunk if it has content\n",
    "if current_chunk:\n",
    "    chunks.append(current_chunk.strip())\n",
    "\n",
    "# Convert chunks into a DataFrame for embedding\n",
    "chunk_df = pd.DataFrame({\"text\": chunks})\n",
    "\n",
    "# Inspect the chunked DataFrame\n",
    "print(f\"Number of chunks: {len(chunk_df)}\")\n",
    "print(chunk_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4k/80dptcl93wn3tj14ld1zdd280000gn/T/ipykernel_53508/910863941.py:2: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embed = OpenAIEmbeddings(\n"
     ]
    }
   ],
   "source": [
    "# Initialize the OpenAI embedding model\n",
    "embed = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    openai_api_key=OPENAI_API_KEY,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to Pinecone and create the index\n",
    "# Initialize Pinecone\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\") or input(\"Enter your Pinecone API key: \")\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "# Define the Pinecone index\n",
    "index_name = \"japan-travel-guide\"  # Corrected index name to use lower case alphanumeric characters and hyphens - \"youtube-transcripts-index-updated\"\n",
    "\n",
    "# Delete an existing index if the limit is reached\n",
    "if len(pc.list_indexes()) >= 5:\n",
    "    pc.delete_index(pc.list_indexes()[0].name)  # Extract the name from the IndexModel object\n",
    "\n",
    "if index_name not in pc.list_indexes():\n",
    "    pc.create_index(\n",
    "        index_name,  # Corrected positional argument\n",
    "        dimension=1536,  # Dimension for \"text-embedding-ada-002\"\n",
    "        metric=\"dotproduct\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
    "    )\n",
    "\n",
    "# Connect to the index\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d0644c4699045bc941176bb01a099c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###ChatGBT with Source Metadata\n",
    "\n",
    "# Add source metadata during indexing\n",
    "batch_size = 100  # Define batch size for efficiency\n",
    "\n",
    "# Process the DataFrame in batches\n",
    "for i in tqdm(range(0, len(chunk_df), batch_size)):\n",
    "    i_end = min(len(chunk_df), i + batch_size)\n",
    "    batch = chunk_df.iloc[i:i_end]\n",
    "\n",
    "    # Extract chunks for embedding\n",
    "    documents = batch[\"text\"].tolist()\n",
    "\n",
    "    # Create embeddings for the text\n",
    "    embeds = embed.embed_documents(documents)\n",
    "\n",
    "    # Generate unique IDs and add source metadata\n",
    "    ids = [f\"chunk-{i+j}\" for j in range(len(batch))]\n",
    "    metadata = [{\"text\": chunk, \"source\": f\"chunk-{i+j}\"} for j, chunk in enumerate(documents)]\n",
    "\n",
    "    # Add embeddings and metadata to Pinecone\n",
    "    index.upsert(vectors=zip(ids, embeds, metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search Results:\n",
      "Chunk ID: chunk-230\n",
      "Score: 0.865899384\n",
      "Matched Text: f you are with a party, the little booths can open up, so you can be next to them. But it's super great if you\n",
      "don't like to see people. It's super well-thought out. I also want to point out in the bathroom, it has the most rolls of toilet paper I have ever seen on a wall before. It was amazing. Well, let me tell you,\n",
      "if you come to Fukuoka, check out Ichiran, the\n",
      "ramen is really good and you don't have to talk to anybody. Well, I hope you enjoyed this video. If this was your first time here, please click here to subscribe, or click here and here to\n",
      "watch some of my other videos. Thanks, bye bye! for some of the best shopping in Fukuoka visit Canal City this huge complex right here it's called a city in a city it's that big it's Japan's largest private development ever there's a canal thatruns right through the middle of it there's a fountain show in the center complex hundreds of shops there's the Grand Hyatt Hotel that's just right here movie theaters arcades a pretty amazing place I will point out the fountain shows every 30 minutes and I was kind of surprised it's actually an outdoor mall so if it's a cold or rainy day well just be married you won't be warm and toasty inside well at least not the mall walkways maybe inside the stores which is probably why they want you to be if you're hungry while you're in Canal City head up to the fifth floor to the ramen Stadium the ramen stadium there eight count of eight different ramen restaurants all right next to each other the great thing about these places actually I'm going to show you right here is they've all got big pictures of the food so you know what you're gonna get and the eggs here I highly encourage you to get some eggs in your ramen the eggs in Japan yellower and tastier than eggs in a lot of place I've been to and to order at most of these restaurants you order out of a vending machine and you just kind of have the vending machine you pick what you want you insert your money you get a ticket and that's how you get your food this region hookah loca specializes in Hakata ramen which is a kind of a clear broth with thin noodles so make sure if you want something famous to get one that's specialized in Hakata ramen and for dessert down in the canal level get yourself some crepes there's a place called differ dance and they sell japanese-style crepes if you've never had japanese-style crepe they roll up and have many interesting toppings they've got like 45 different crepes this one has banana strawberry whipped cream and pudding have you ever had a crepe with pudding in it that is also served with a spoon so that you can eat it out of there hmm I love the pudding in Japan and great it's not much better okay so I talked about the fountain show earlier but I really wanted to show it to you do not think this is like any other lame mall fountain show the Canal City fountain show will make all other fountain shows look pretty lame in comparison I mean it's not quite as big as the Bellagio fountains in Las Vegas but I do feel the production quality and how close you can get to the fountains make it really impressive it's hard to capture all of it on camera particularly because I didn't want to get my lens super wet but when you come to Fukuoka make sure to check out the fountain show at Canal City super awesome alright thanks for watching if this is your first time here please click on this yellow ball to subscribe follow us on Facebook Twitter Google+ link the description below or watch one of these other videos alright thanks bye bye [Music] hey everybody I am in Fukuoka today and what am i eating what did I fly halfway around the world in Japan tea is it sushi no in the ramen I already had that twice yesterday today putting it the Tianjin train station there's a shop just outside called the Hakata west street pudding shop and you know what they sell pudding and you know what else they sell nothing all pudding it's entire shop dedicated putting the\n"
     ]
    }
   ],
   "source": [
    "#direct queries to the Pinecone index - just to test if it works\n",
    "# Query the Pinecone index\n",
    "query = \"Where can you find the best Ramen in Tokyo?\" # Examples:How much percent of Japan's population live in Tokyo?\n",
    "query_embedding = embed.embed_query(query)\n",
    "\n",
    "# Search the index with metadata included\n",
    "search_results = index.query(vector=query_embedding, top_k=1, include_metadata=True)\n",
    "\n",
    "# Display the result\n",
    "print(\"Search Results:\")\n",
    "for result in search_results[\"matches\"]:\n",
    "    print(f\"Chunk ID: {result['id']}\")\n",
    "    print(f\"Score: {result['score']}\")\n",
    "    if \"metadata\" in result and \"text\" in result[\"metadata\"]:\n",
    "        print(f\"Matched Text: {result['metadata']['text']}\")\n",
    "    else:\n",
    "        print(\"No metadata found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.chains import RetrievalQA, RetrievalQAWithSourcesChain\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4k/80dptcl93wn3tj14ld1zdd280000gn/T/ipykernel_53508/1080470363.py:6: LangChainDeprecationWarning: The class `Pinecone` was deprecated in LangChain 0.0.18 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-pinecone package and should be used instead. To use it run `pip install -U :class:`~langchain-pinecone` and import as `from :class:`~langchain_pinecone import Pinecone``.\n",
      "  vectorstore = Pinecone(\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Define metadata field for text\n",
    "text_field = \"text\"\n",
    "\n",
    "# Initialize the vector store using the Pinecone index you've created ->  initialzie so I can access Database\n",
    "vectorstore = Pinecone(\n",
    "    index=index,  # Use the `index` object you already initialized in Step 2\n",
    "    embedding=embed,  # Pass the embedding object\n",
    "    text_key=text_field  # Key for metadata\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
